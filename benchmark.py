"""
benchmark.py
------------
Benchmark different membership testing methods on synthetic datasets.

Methods:
    - Linear search (only for smaller datasets: 10K, 100K, 1M)
    - Binary search
    - Hash set
    - Bloom filter
    - Cuckoo filter

Input:
    Reads from CSV files generated by synth_dataset.py:
        logins_N.csv, queries_Q.csv

Output:
    - Prints runtime, accuracy, FP, FN for each method.
    - Plots:
        1. Linear search runtimes for N = 10K, 100K, 1M
        2. Runtime comparison of Hash, Bloom, Cuckoo, Binary for all N values
"""

import csv
import time
import bisect
import matplotlib.pyplot as plt
from pybloom_live import BloomFilter
from cuckoopy import CuckooFilter

# ---------------------------------------------------
# Load dataset
# ---------------------------------------------------
def load_logins(filename):
    """Load usernames from a logins CSV file."""
    with open(filename, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        return [row["username"] for row in reader]

def load_queries(filename):
    """Load queries as (username, is_present) pairs."""
    queries = []
    with open(filename, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            queries.append((row["username"], int(row["is_present"])))
    return queries

# ---------------------------------------------------
# Membership methods with correctness tracking
# Each returns (runtime, tp, tn, fp, fn)
# ---------------------------------------------------
def run_linear(logins, queries):
    start = time.time()
    tp=tn=fp=fn=0
    for q, truth in queries:
        found = q in logins
        if found and truth==1: tp+=1
        elif not found and truth==0: tn+=1
        elif found and truth==0: fp+=1
        elif not found and truth==1: fn+=1
    return time.time()-start, tp, tn, fp, fn

def run_binary(logins, queries):
    sorted_logins = sorted(logins)
    start = time.time()
    tp=tn=fp=fn=0
    for q, truth in queries:
        i = bisect.bisect_left(sorted_logins, q)
        found = (i < len(sorted_logins) and sorted_logins[i]==q)
        if found and truth==1: tp+=1
        elif not found and truth==0: tn+=1
        elif found and truth==0: fp+=1
        elif not found and truth==1: fn+=1
    return time.time()-start, tp, tn, fp, fn

def run_hash(logins, queries):
    login_set = set(logins)
    start = time.time()
    tp=tn=fp=fn=0
    for q, truth in queries:
        found = q in login_set
        if found and truth==1: tp+=1
        elif not found and truth==0: tn+=1
        elif found and truth==0: fp+=1
        elif not found and truth==1: fn+=1
    return time.time()-start, tp, tn, fp, fn

def run_bloom(logins, queries):
    bloom = BloomFilter(capacity=len(logins), error_rate=0.001)
    for u in logins: bloom.add(u)
    start = time.time()
    tp=tn=fp=fn=0
    for q, truth in queries:
        found = q in bloom
        if found and truth==1: tp+=1
        elif not found and truth==0: tn+=1
        elif found and truth==0: fp+=1
        elif not found and truth==1: fn+=1
    return time.time()-start, tp, tn, fp, fn

def run_cuckoo(logins, queries):
    cuckoo = CuckooFilter(capacity=len(logins), bucket_size=2, fingerprint_size=4)
    for u in logins: cuckoo.insert(u)
    start = time.time()
    tp=tn=fp=fn=0
    for q, truth in queries:
        found = cuckoo.contains(q)
        if found and truth==1: tp+=1
        elif not found and truth==0: tn+=1
        elif found and truth==0: fp+=1
        elif not found and truth==1: fn+=1
    return time.time()-start, tp, tn, fp, fn

# ---------------------------------------------------
# Benchmark runner
# ---------------------------------------------------
def benchmark_methods(n_values, q_values):
    linear_results = {}
    other_results = {m:{} for m in ["Binary","Hash","Bloom","Cuckoo"]}

    for n,q in zip(n_values,q_values):
        logins = load_logins(f"logins_{n}.csv")
        queries = load_queries(f"queries_{q}.csv")

        print(f"\nDataset size: n={n}, q={q}")

        # Linear only for smaller sets
        if n <= 1_000_000:
            runtime,tp,tn,fp,fn = run_linear(logins, queries)
            linear_results[n] = runtime
            print(f" Linear: time={runtime:.4f}s, acc={(tp+tn)/(tp+tn+fp+fn):.4f}, FP={fp}, FN={fn}")

        # Other methods for all sets
        for name, func in [("Binary",run_binary),("Hash",run_hash),("Bloom",run_bloom),("Cuckoo",run_cuckoo)]:
            if name == "Cuckoo" and n == 100_000_000:
                print(" Cuckoo: skipped at n=100M (too large for memory/runtime)")
                continue
            runtime,tp,tn,fp,fn = func(logins, queries)
            other_results[name][n] = runtime
            print(f" {name}: time={runtime:.4f}s, acc={(tp+tn)/(tp+tn+fp+fn):.4f}, FP={fp}, FN={fn}")

    return linear_results, other_results

# ---------------------------------------------------
# Plotting
# ---------------------------------------------------
def plot_results(linear_results, other_results, n_values):
    colors = ["#3bcee8","#1f77b4","#ff69b4","#ff00d9","#800080"]

    # Linear search plot
    plt.figure(figsize=(7,5))
    plt.bar([str(n) for n in linear_results.keys()], linear_results.values(), color=colors[:len(linear_results)])
    for i,(n,rt) in enumerate(linear_results.items()):
        plt.text(i, rt, f"{rt:.2f}s", ha="center", va="bottom")
    plt.title("Linear Search Runtime (only small datasets)")
    plt.xlabel("Dataset size (n)")
    plt.ylabel("Runtime (seconds)")
    plt.show()

    # Other methods plot
    plt.figure(figsize=(10,6))

    methods = list(other_results.keys())   # ["Binary","Hash","Bloom","Cuckoo"]
    x = range(len(methods))
    bar_width = 0.15

    # Colors for each dataset size
    colors = ["#3bcee8","#1f77b4","#ff69b4","#ff00d9","#800080"]

    for j, n in enumerate(n_values):
        runtimes = [other_results[m].get(n, None) for m in methods]
        filtered_x = [xi + j*bar_width for xi, rt in zip(x, runtimes) if rt is not None]
        filtered_rt = [rt for rt in runtimes if rt is not None]
        plt.bar(filtered_x, filtered_rt, width=bar_width, 
                color=colors[j % len(colors)], label=f"n={n}, q={q_values[j]}")

        # Add labels above bars
        for xi, rt in zip(filtered_x, filtered_rt):
            plt.text(xi, rt, f"{rt:.2f}s", ha="center", va="bottom", fontsize=8)

    plt.title("Runtime Comparison Across Dataset Sizes")
    plt.xlabel("Method")
    plt.ylabel("Runtime (seconds)")
    plt.xticks([xi + (len(n_values)/2)*bar_width for xi in x], methods)
    plt.legend()
    plt.show()
    
# ---------------------------------------------------
# Main
# ---------------------------------------------------
if __name__ == "__main__":
    n_values = [10_000, 100_000, 1_000_000, 10_000_000, 100_000_000]
    q_values = [1_000, 10_000, 100_000, 1_000_000, 10_000_000]

    linear_results, other_results = benchmark_methods(n_values, q_values)
    plot_results(linear_results, other_results, n_values)
